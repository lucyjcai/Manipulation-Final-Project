{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f200d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "from pydrake.all import (\n",
    "    BasicVector,\n",
    "    Context,\n",
    "    DiagramBuilder,\n",
    "    LeafSystem,\n",
    "    MultibodyPlant,\n",
    "    RigidTransform,\n",
    "    RotationMatrix,\n",
    "    Simulator,\n",
    "    Trajectory, \n",
    "    PiecewisePolynomial,\n",
    "    PiecewisePose,\n",
    "    JacobianWrtVariable,\n",
    "    StartMeshcat,\n",
    "    TrajectorySource,\n",
    "    Integrator,\n",
    "    \n",
    ")\n",
    "\n",
    "from manipulation.station import (\n",
    "    LoadScenario,\n",
    "    MakeHardwareStation,\n",
    ")\n",
    "import h5py\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aeb0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshcat = StartMeshcat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5139b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_drawer_pose(\n",
    "    r_min=0.40,      \n",
    "    r_max=0.45,     \n",
    "    fov_deg=90, \n",
    "    face_noise_deg=30,\n",
    "    cabinet_depth=1,\n",
    "    cabinet_width=1,    \n",
    "):\n",
    "    \"\"\"\n",
    "    Returns (x, y, yaw_degrees)\n",
    "    \"\"\"\n",
    "    r = random.uniform(r_min, r_max)\n",
    "    print(r)\n",
    "    theta_rad = np.radians(random.uniform(270-fov_deg/2, 270+fov_deg/2))\n",
    "    \n",
    "    x = r * np.cos(theta_rad)\n",
    "    y = r * np.sin(theta_rad)\n",
    "    \n",
    "    \n",
    "    # Adjust angle b/w drawer origin is bottom right corner of cabinet\n",
    "    perfect_yaw_rad = np.arctan2(-y, -x)\n",
    "    yaw_rad = perfect_yaw_rad + np.radians(random.uniform(-face_noise_deg, face_noise_deg))\n",
    "    \n",
    "    local_center_x = cabinet_depth / 2.0\n",
    "    local_center_y = cabinet_width / 2.0\n",
    "    \n",
    "    c_yaw = np.cos(yaw_rad)\n",
    "    s_yaw = np.sin(yaw_rad)\n",
    "    \n",
    "    world_offset_x = local_center_x * c_yaw - local_center_y * s_yaw\n",
    "    world_offset_y = local_center_x * s_yaw + local_center_y * c_yaw\n",
    "    \n",
    "    final_origin_x = x - world_offset_x\n",
    "    final_origin_y = y - world_offset_y\n",
    "    \n",
    "    return final_origin_x, final_origin_y, np.degrees(yaw_rad)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa53dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scenario_string(drawer_name = \"label62\", **kwargs) -> str:\n",
    "    drawer_urdf_path = f\"{Path.cwd()}/urdf/custom/output/{drawer_name}.urdf\"\n",
    "    \n",
    "    x, y, yaw = get_random_drawer_pose(**kwargs)\n",
    "    \n",
    "    scenario_string = f\"\"\"\n",
    "    directives:\n",
    "    # add robot\n",
    "    - add_model:\n",
    "        name: iiwa\n",
    "        file: package://drake_models/iiwa_description/urdf/iiwa14_primitive_collision.urdf\n",
    "        default_joint_positions:\n",
    "            iiwa_joint_1: [-1.57]\n",
    "            iiwa_joint_2: [0.1]\n",
    "            iiwa_joint_3: [0]\n",
    "            iiwa_joint_4: [-1.2]\n",
    "            iiwa_joint_5: [0]\n",
    "            iiwa_joint_6: [1.6]\n",
    "            iiwa_joint_7: [0]\n",
    "    - add_weld:\n",
    "        parent: world\n",
    "        child: iiwa::iiwa_link_0\n",
    "\n",
    "    # add gripper\n",
    "    - add_model:\n",
    "        name: wsg\n",
    "        file: package://manipulation/hydro/schunk_wsg_50_with_tip.sdf\n",
    "    - add_weld:\n",
    "        parent: iiwa::iiwa_link_7\n",
    "        child: wsg::body\n",
    "        X_PC:\n",
    "            translation: [0, 0, 0.09]\n",
    "            rotation: !Rpy {{ deg: [90, 0, 90]}}\n",
    "\n",
    "    # add camera mounted to world \n",
    "    - add_frame:\n",
    "        name: camera0_origin\n",
    "        X_PF:\n",
    "            base_frame: world\n",
    "            rotation: !Rpy {{ deg: [250, 0, 180.0]}}\n",
    "            translation: [0, 2, 1.4]\n",
    "    - add_model:\n",
    "        name: camera0\n",
    "        file: package://manipulation/camera_box.sdf\n",
    "    - add_weld:\n",
    "        parent: camera0_origin\n",
    "        child: camera0::base\n",
    "\n",
    "    # add camera mounted to robot wrist\n",
    "    - add_frame:\n",
    "        name: camera_wrist\n",
    "        X_PF:\n",
    "            base_frame: iiwa::iiwa_link_7\n",
    "            translation: [-0.05, 0, 0.07]   \n",
    "            rotation: !Rpy {{deg: [0, 0, -90]}}\n",
    "    - add_model:\n",
    "        name: camera1\n",
    "        file: package://manipulation/camera_box.sdf\n",
    "    - add_weld:\n",
    "        parent: iiwa::camera_wrist\n",
    "        child: camera1::base\n",
    "\n",
    "    # add camera mounted to world pointing top down\n",
    "    - add_frame:\n",
    "        name: camera2_origin\n",
    "        X_PF:\n",
    "            base_frame: world\n",
    "            rotation: !Rpy {{ deg: [0, 180.0, 0.0]}}\n",
    "            translation: [0, -0.5, 3.0]\n",
    "    - add_model:\n",
    "        name: camera2\n",
    "        file: package://manipulation/camera_box.sdf\n",
    "    - add_weld:\n",
    "        parent: camera2_origin\n",
    "        child: camera2::base\n",
    "        \n",
    "    # add random drawer\n",
    "    - add_model:\n",
    "        name: drawer\n",
    "        file: file://{drawer_urdf_path}\n",
    "    - add_frame:\n",
    "        name: drawer_origin\n",
    "        X_PF:\n",
    "            base_frame: world\n",
    "            translation: [{x}, {y}, 0]    \n",
    "            rotation: !Rpy {{ deg: [0, 0, {yaw}]}}  \n",
    "    - add_weld:\n",
    "        parent: drawer_origin\n",
    "        child: drawer::base_link\n",
    "        \n",
    "    cameras:\n",
    "        camera0:\n",
    "            name: camera0\n",
    "            depth: True\n",
    "            X_PB:\n",
    "                base_frame: camera0::base\n",
    "        camera1:\n",
    "            name: camera1\n",
    "            depth: True\n",
    "            focal: !FovDegrees\n",
    "                x: 110   # horizontal FOV in degrees\n",
    "            X_PB:\n",
    "                base_frame: camera1::base\n",
    "        camera2:\n",
    "            name: camera2\n",
    "            depth: True\n",
    "            X_PB:\n",
    "                base_frame: camera2::base\n",
    "    \n",
    "    model_drivers:\n",
    "        iiwa: !IiwaDriver\n",
    "            control_mode: position_only \n",
    "            hand_model_name: wsg\n",
    "        wsg: !SchunkWsgDriver {{}}\n",
    "    \"\"\"\n",
    "    return scenario_string\n",
    "\n",
    "scenario_string = generate_scenario_string()\n",
    "scenario = LoadScenario(data=scenario_string)\n",
    "station = MakeHardwareStation(scenario, meshcat=meshcat)\n",
    "builder = DiagramBuilder()\n",
    "builder.AddSystem(station)\n",
    "diagram = builder.Build()\n",
    "context = diagram.CreateDefaultContext()\n",
    "\n",
    "simulator = Simulator(diagram)\n",
    "simulator.set_target_realtime_rate(1.0)\n",
    "simulator.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grasp_pose(X_WO: RigidTransform) -> RigidTransform:\n",
    "    p_OG = np.array([0.122, 0, 0]) \n",
    "    \n",
    "    R_OG = RotationMatrix.MakeZRotation(np.pi/2).multiply(RotationMatrix.MakeYRotation(np.pi))\n",
    "    \n",
    "    X_OG = RigidTransform(R_OG, p_OG)\n",
    "    X_WG = X_WO @ X_OG\n",
    "    return X_WG\n",
    "\n",
    "def approach_pose(X_WG: RigidTransform) -> RigidTransform:\n",
    "    p_GGApproach = [0, -0.1, 0] \n",
    "    X_GGApproach = RigidTransform(RotationMatrix(), p_GGApproach)\n",
    "    X_WGApproach = X_WG @ X_GGApproach\n",
    "    return X_WGApproach\n",
    "\n",
    "def goal_pose(X_W_Grasporiginal: RigidTransform, X_W_Handle: RigidTransform) -> RigidTransform:\n",
    "    v_obj_move = np.array([0.3, 0, 0]) \n",
    "    v_world_move = X_W_Handle.rotation().multiply(v_obj_move)\n",
    "    \n",
    "    p_W_Grasp = X_W_Grasporiginal.translation()\n",
    "    p_W_Goal = p_W_Grasp + v_world_move\n",
    "    \n",
    "    X_W_Graspgoal = RigidTransform(X_W_Grasporiginal.rotation(), p_W_Goal)\n",
    "    return X_W_Graspgoal\n",
    "\n",
    "def post_goal_pose(X_WGgoal: RigidTransform, X_W_Handle: RigidTransform) -> RigidTransform:\n",
    "    v_obj_move = np.array([0.23,0, 0]) \n",
    "    \n",
    "    v_world_move = X_W_Handle.rotation().multiply(v_obj_move)\n",
    "    \n",
    "    p_W_Ggoal = X_WGgoal.translation()\n",
    "    p_W_Gpostgoal = p_W_Ggoal + v_world_move\n",
    "    \n",
    "    X_W_Gpostgoal = RigidTransform(X_WGgoal.rotation(), p_W_Gpostgoal)\n",
    "    return X_W_Gpostgoal\n",
    "\n",
    "def make_trajectory_pose(\n",
    "    X_Gs: list[RigidTransform], finger_values: np.ndarray, sample_times: list[float]\n",
    ") -> tuple[Trajectory, PiecewisePolynomial]:\n",
    "    poses = PiecewisePose.MakeLinear(sample_times, X_Gs)\n",
    "    \n",
    "    robot_velocity_trajectory = poses.MakeDerivative()\n",
    "    traj_wsg_command = PiecewisePolynomial.FirstOrderHold(sample_times, finger_values)\n",
    "    return robot_velocity_trajectory, traj_wsg_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a100b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoInverseController(LeafSystem):\n",
    "    def __init__(self, plant: MultibodyPlant):\n",
    "        LeafSystem.__init__(self)\n",
    "        self._plant = plant\n",
    "        self._plant_context = plant.CreateDefaultContext()\n",
    "        self._iiwa = plant.GetModelInstanceByName(\"iiwa\")\n",
    "        self._G = plant.GetBodyByName(\"body\").body_frame() \n",
    "        self._W = plant.world_frame()\n",
    "\n",
    "        # Declaring the ports\n",
    "        self.V_G_port = self.DeclareVectorInputPort(\"V_WG\", 6)\n",
    "        self.q_port = self.DeclareVectorInputPort(\"iiwa.position\", 7)\n",
    "        self.DeclareVectorOutputPort(\"iiwa.velocity\", 7, self.CalcOutput)\n",
    "        self.iiwa_start = plant.GetJointByName(\"iiwa_joint_1\").velocity_start()\n",
    "        self.iiwa_end = plant.GetJointByName(\"iiwa_joint_7\").velocity_start()\n",
    "\n",
    "    def CalcOutput(self, context: Context, output: BasicVector):\n",
    "        V_WG_desired = self.V_G_port.Eval(context)\n",
    "        q = self.q_port.Eval(context)\n",
    "        self._plant.SetPositions(self._plant_context, self._iiwa, q)\n",
    "    \n",
    "        # Using the jacobian to determine the desired joint velocity\n",
    "        J_G_W = self._plant.CalcJacobianSpatialVelocity(\n",
    "            self._plant_context,\n",
    "            JacobianWrtVariable.kQDot,\n",
    "            self._G, \n",
    "            [0, 0, 0], \n",
    "            self._W, \n",
    "            self._W,\n",
    "        )\n",
    "        \n",
    "        # Extract the values corresponding to the IIWA joints\n",
    "        J_iiwa = J_G_W[:, self.iiwa_start : self.iiwa_end + 1]\n",
    "\n",
    "        # Damp least squares to fix near singularity issues\n",
    "        # higher lambda -> more staable but less accurate\n",
    "        lambda_val = 0.004\n",
    "        \n",
    "        # Formula: v = J.T * inv(J * J.T + lambda^2 * I) * V_desired\n",
    "        J_T = J_iiwa.T\n",
    "        n_rows = J_iiwa.shape[0] # 6\n",
    "        \n",
    "        # Calculate (J * J.T + lambda^2 * I)\n",
    "        M = J_iiwa @ J_T + (lambda_val**2) * np.eye(n_rows)\n",
    "        \n",
    "        v_task = J_T @ np.linalg.solve(M, V_WG_desired)\n",
    "\n",
    "\n",
    "        # Null space control to fix near joint limitations\n",
    "        \n",
    "        # values close to limits of joints\n",
    "        q_nominal = np.array([0, 0.6, 0, -1.2, 0, 1.6, 0]) \n",
    "        \n",
    "        kp_null = 5.0 \n",
    "        v_secondary_desired = kp_null * (q_nominal - q)\n",
    "        \n",
    "        J_pinv = np.linalg.pinv(J_iiwa) \n",
    "        n_joints = J_iiwa.shape[1] # 7\n",
    "        P = np.eye(n_joints) - (J_pinv @ J_iiwa)\n",
    "        \n",
    "        v_null = P @ v_secondary_desired\n",
    "\n",
    "        # Combine\n",
    "        v_total = v_task + v_null\n",
    "        \n",
    "        v_clamped = np.clip(v_total, -2.0, 2.0)\n",
    "\n",
    "        output.SetFromVector(v_clamped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "WSG_MIN = 0.0        # fully closed width (meters)\n",
    "WSG_MAX = 0.1        # fully open width (meters)\n",
    "\n",
    "def normalize_wsg(width):\n",
    "    return np.clip((width - WSG_MIN) / (WSG_MAX - WSG_MIN), 0.0, 1.0)\n",
    "\n",
    "def unnormalize_wsg(norm_width):\n",
    "    return WSG_MIN + norm_width * (WSG_MAX - WSG_MIN)\n",
    "\n",
    "# TODO: figure out real velocity limit in simulation by closing/opening grippers\n",
    "WSG_MAX_SPEED = 0.4  # meters/sec width change\n",
    "\n",
    "def normalize_wsg_velocity(width_velocity):\n",
    "    v = width_velocity / WSG_MAX_SPEED\n",
    "    return np.clip(v, -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ca905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trajectory(scenario_string):\n",
    "    # Initializing \n",
    "    scenario = LoadScenario(data=scenario_string)\n",
    "    builder = DiagramBuilder()\n",
    "    station = MakeHardwareStation(scenario, meshcat=meshcat)\n",
    "    builder.AddSystem(station)\n",
    "    plant = station.GetSubsystemByName(\"plant\")\n",
    "\n",
    "    # Get initial poses of gripper and objects\n",
    "    temp_context = station.CreateDefaultContext()\n",
    "    temp_plant_context = plant.GetMyContextFromRoot(temp_context)\n",
    "    drawer_model_instance = plant.GetModelInstanceByName(\"drawer\")\n",
    "    wsg_model = plant.GetModelInstanceByName(\"wsg\")\n",
    "    iiwa_model = plant.GetModelInstanceByName(\"iiwa\")\n",
    "\n",
    "\n",
    "    \n",
    "    handle_body = plant.GetBodyByName(\"handle3\", drawer_model_instance)\n",
    "    X_W_Handle = plant.EvalBodyPoseInWorld(temp_plant_context, handle_body)\n",
    "\n",
    "    gripper_body = plant.GetBodyByName(\"body\", wsg_model)\n",
    "    \n",
    "    \n",
    "    # Designing the poses (expert trajcetory)\n",
    "    X_W_GripInitial = plant.EvalBodyPoseInWorld(temp_plant_context, gripper_body)\n",
    "    X_W_Grasp = grasp_pose(X_W_Handle)\n",
    "    X_W_Pregrasp = approach_pose(X_W_Grasp)\n",
    "    X_W_Graspgoal = goal_pose(X_W_Grasp, X_W_Handle) \n",
    "    X_W_Gpostgoal = post_goal_pose(X_W_Graspgoal, X_W_Handle)\n",
    "    \n",
    "    opened = 0.107\n",
    "    closed = 0.0\n",
    "\n",
    "    keyframes = [\n",
    "        (X_W_GripInitial, opened), (X_W_Pregrasp, opened), (X_W_Grasp, opened), \n",
    "        (X_W_Grasp, closed), (X_W_Graspgoal, closed), (X_W_Graspgoal, opened), (X_W_Gpostgoal, opened)\n",
    "    ]\n",
    "\n",
    "    \n",
    "    # # Finding and adding the trajectory\n",
    "    gripper_poses = [keyframe[0] for keyframe in keyframes]\n",
    "    finger_states = np.asarray([keyframe[1] for keyframe in keyframes]).reshape(1, -1)\n",
    "    sample_times = [2 * i for i in range(len(gripper_poses))]\n",
    "    traj_V_G, traj_wsg_command = make_trajectory_pose(gripper_poses, finger_states, sample_times)\n",
    "\n",
    "    V_G_source = builder.AddSystem(TrajectorySource(traj_V_G))\n",
    "    wsg_source = builder.AddSystem(TrajectorySource(traj_wsg_command))\n",
    "    controller = builder.AddSystem(PseudoInverseController(plant))\n",
    "    integrator = builder.AddSystem(Integrator(7))\n",
    "\n",
    "\n",
    "    # Connect Ports\n",
    "    builder.Connect(V_G_source.get_output_port(0), controller.GetInputPort(\"V_WG\"))\n",
    "    builder.Connect(station.GetOutputPort(\"iiwa.position_measured\"), controller.GetInputPort(\"iiwa.position\"))\n",
    "    builder.Connect(controller.get_output_port(0), integrator.get_input_port(0))\n",
    "    \n",
    "    # Crucial: We are connecting Integrator -> Station. \n",
    "    # This means the Integrator Output IS the Action.\n",
    "    builder.Connect(integrator.get_output_port(0), station.GetInputPort(\"iiwa.position\"))\n",
    "    builder.Connect(wsg_source.get_output_port(0), station.GetInputPort(\"wsg.position\"))\n",
    "\n",
    "    diagram = builder.Build()\n",
    "\n",
    "    # Define the simulator\n",
    "    simulator = Simulator(diagram)\n",
    "    context = simulator.get_mutable_context()\n",
    "    station_context = station.GetMyContextFromRoot(context)\n",
    "    integrator.set_integral_value(\n",
    "        integrator.GetMyContextFromRoot(context),\n",
    "        plant.GetPositions(\n",
    "            plant.GetMyContextFromRoot(context),\n",
    "            iiwa_model,\n",
    "        ),\n",
    "    )\n",
    "    diagram.ForcedPublish(context)\n",
    "    print(f\"sanity check, simulation will run for {traj_V_G.end_time()} seconds\")\n",
    "\n",
    "    # # run simulation\n",
    "    meshcat.StartRecording()\n",
    "    simulator.set_target_realtime_rate(1)\n",
    "\n",
    "    # 5. DATA LOGGING SETUP\n",
    "    target_dt = 0.05 # 20 Hz\n",
    "    image_data_camera0 = []\n",
    "    image_data_camera1 = []\n",
    "    image_data_camera2 = []\n",
    "    timestamps = []\n",
    "    qpos_list = []\n",
    "    qvel_list = []\n",
    "    action_list = []\n",
    "\n",
    "    total_duration = traj_V_G.end_time()\n",
    "    print(f\"Starting collection... running for {total_duration} seconds.\")\n",
    "\n",
    "    # 6. EXECUTION LOOP\n",
    "    t = 0.0\n",
    "    \n",
    "    while t <= total_duration:\n",
    "        simulator.AdvanceTo(t)\n",
    "        t = simulator.get_context().get_time()\n",
    "\n",
    "        sim_context = simulator.get_context()\n",
    "        station_context = diagram.GetSubsystemContext(station, sim_context)\n",
    "        plant_context = station.GetSubsystemContext(plant, station_context)\n",
    "        \n",
    "        # iiwa joints\n",
    "        q_iiwa = plant.GetPositions(plant_context, iiwa_model)\n",
    "        v_iiwa = plant.GetVelocities(plant_context, iiwa_model)\n",
    "        \n",
    "        # gripper joins\n",
    "        q_wsg = plant.GetPositions(plant_context, wsg_model)\n",
    "        v_wsg = plant.GetVelocities(plant_context, wsg_model)\n",
    "        wsg_width = normalize_wsg(q_wsg[1] - q_wsg[0])\n",
    "        wsg_vel = normalize_wsg_velocity(v_wsg[1] - v_wsg[0])\n",
    "\n",
    "        # concatenate to get exactly (7 + 1,) vectors\n",
    "        qpos = np.concatenate([q_iiwa, [wsg_width]], axis=0).copy()\n",
    "        qvel = np.concatenate([v_iiwa, [wsg_vel]], axis=0).copy()\n",
    "        qpos_list.append(qpos)\n",
    "        qvel_list.append(qvel)\n",
    "\n",
    "        # D. Get Actions (Commands)\n",
    "        # We extract what the controller/trajectory is SENDING to the robot this step.\n",
    "        # For iiwa: Output of Integrator\n",
    "        integrator_context = diagram.GetSubsystemContext(integrator, sim_context)\n",
    "        iiwa_cmd = integrator.get_output_port(0).Eval(integrator_context)\n",
    "        \n",
    "        # For wsg: Output of TrajectorySource\n",
    "        wsg_source_context = diagram.GetSubsystemContext(wsg_source, sim_context)\n",
    "        wsg_cmd_raw = wsg_source.get_output_port(0).Eval(wsg_source_context)\n",
    "        wsg_cmd_norm = normalize_wsg(wsg_cmd_raw[0]) # Normalize strictly for data consistency\n",
    "\n",
    "        # Flatten and concatenate\n",
    "        iiwa_cmd_np = np.asarray(iiwa_cmd).ravel()\n",
    "        wsg_cmd_np = np.asarray([wsg_cmd_norm]).ravel()\n",
    "        action = np.concatenate([iiwa_cmd_np, wsg_cmd_np], axis=0)\n",
    "        action_list.append(action)\n",
    "\n",
    "        # E. Get Images\n",
    "        # Camera 0\n",
    "        img0 = station.GetOutputPort(\"camera0.rgb_image\").Eval(station_context)\n",
    "        np_img0 = np.array(np.copy(img0.data)).reshape(img0.height(), img0.width(), -1)\n",
    "        image_data_camera0.append(np_img0[:, :, :3].copy()) # Keep RGB only\n",
    "        \n",
    "        # Camera 1\n",
    "        img1 = station.GetOutputPort(\"camera1.rgb_image\").Eval(station_context)\n",
    "        np_img1 = np.array(np.copy(img1.data)).reshape(img1.height(), img1.width(), -1)\n",
    "        image_data_camera1.append(np_img1[:, :, :3].copy())\n",
    "\n",
    "        # Camera 2\n",
    "        img2 = station.GetOutputPort(\"camera2.rgb_image\").Eval(station_context)\n",
    "        np_img2 = np.array(np.copy(img2.data)).reshape(img2.height(), img2.width(), -1)\n",
    "        image_data_camera2.append(np_img2[:, :, :3].copy())\n",
    "\n",
    "        timestamps.append(t)\n",
    "        t += target_dt\n",
    "\n",
    "    print(\"Trajectory execution and logging complete.\")\n",
    "    meshcat.StopRecording()\n",
    "    meshcat.PublishRecording()\n",
    "\n",
    "    # 7. Return Dictionary (Standard ACT/Imitation Learning format)\n",
    "    return {\n",
    "        \"qpos\": qpos_list,\n",
    "        \"qvel\": qvel_list,\n",
    "        \"action\": action_list,\n",
    "        \"images\": {\n",
    "            \"camera0\": image_data_camera0,\n",
    "            \"camera1\": image_data_camera1,\n",
    "            \"camera2\": image_data_camera2\n",
    "        },\n",
    "        \"timestamp\": timestamps\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2638d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trajectory_data(data: dict, episode_idx: int = 0):\n",
    "    # ---------- convert buffers to numpy arrays ----------\n",
    "    qpos_arr = np.stack(data['qpos'], axis=0).astype(np.float32)      # (T, nq)\n",
    "    qvel_arr = np.stack(data['qvel'], axis=0).astype(np.float32)      # (T, nq)\n",
    "    action_arr = np.stack(data['action'], axis=0).astype(np.float32)  # (T, act_dim)\n",
    "\n",
    "    images0_arr = np.stack(data['images']['camera0'], axis=0).astype(np.uint8)  # (T, H, W, 3)\n",
    "    images1_arr = np.stack(data['images']['camera1'], axis=0).astype(np.uint8)  # (T, H, W, 3)\n",
    "    images2_arr = np.stack(data['images']['camera2'], axis=0).astype(np.uint8)  # (T, H, W, 3)\n",
    "\n",
    "    timestamps_arr = np.array(data['timestamp'], dtype=np.float64)\n",
    "\n",
    "    # ---------- write ACT-style HDF5 episode ----------\n",
    "    h5_path = os.path.join(\"teleop_data/sim_open_drawer\", f\"episode_{episode_idx}.hdf5\")\n",
    "    print(\"Saving episode to \", h5_path)\n",
    "\n",
    "    with h5py.File(h5_path, \"w\") as root:\n",
    "        # mark this as simulation data (ACT uses this flag)\n",
    "        root.attrs[\"sim\"] = True\n",
    "\n",
    "        # actions: shape (T, act_dim)\n",
    "        root.create_dataset(\"action\", data=action_arr, compression=\"gzip\")\n",
    "\n",
    "    # observations group\n",
    "        obs_grp = root.create_group(\"observations\")\n",
    "        obs_grp.create_dataset(\"qpos\", data=qpos_arr, compression=\"gzip\")\n",
    "        obs_grp.create_dataset(\"qvel\", data=qvel_arr, compression=\"gzip\")\n",
    "\n",
    "        # optional: store timestamps (not strictly required by ACT but often useful)\n",
    "        obs_grp.create_dataset(\"time\", data=timestamps_arr)\n",
    "\n",
    "        # images subgroup, one dataset per camera\n",
    "        img_grp = obs_grp.create_group(\"images\")\n",
    "        img_grp.create_dataset(\"camera0\", data=images0_arr, compression=\"gzip\")\n",
    "        img_grp.create_dataset(\"camera1\", data=images1_arr, compression=\"gzip\")\n",
    "        img_grp.create_dataset(\"camera2\", data=images2_arr, compression=\"gzip\")\n",
    "\n",
    "    print(f\"Wrote ACT-style episode to {h5_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee2480",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 10\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    meshcat.Delete()\n",
    "    print(f\"Generating episode {i}...\")\n",
    "    # scenario_string = generate_scenario_string(fov_deg = 0, face_noise_deg=0)\n",
    "    scenario_string = generate_scenario_string()\n",
    "    trajectory_data = generate_trajectory(scenario_string)\n",
    "    save_trajectory_data(trajectory_data, episode_idx=i)\n",
    "    print(f\"Episode {i} complete.\\n\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab9eac7",
   "metadata": {},
   "source": [
    "### Watching the demonstration back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio; \n",
    "from IPython.display import Video; \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60198a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_playback = 10\n",
    "for i in range(num_playback):\n",
    "    file_path = f\"teleop_data/sim_open_drawer/episode_{i}.hdf5\"\n",
    "\n",
    "    f = h5py.File(file_path, \"r\")\n",
    "    data = f['observations']['images']['camera0']\n",
    "    frames = []\n",
    "    for i in range(data.shape[0]):\n",
    "        frame = data[i]\n",
    "        frames.append(frame)\n",
    "        \n",
    "\n",
    "    imageio.mimwrite(f'episode_playback_{i}.mp4', data, fps=30); \n",
    "    Video(f'episode_playback_{i}.mp4', width=480, height=360) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5c323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc9526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21169ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
