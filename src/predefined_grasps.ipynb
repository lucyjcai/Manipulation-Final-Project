{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f200d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "from pydrake.all import (\n",
    "    BasicVector,\n",
    "    Context,\n",
    "    DiagramBuilder,\n",
    "    LeafSystem,\n",
    "    MultibodyPlant,\n",
    "    RigidTransform,\n",
    "    RotationMatrix,\n",
    "    Simulator,\n",
    "    Trajectory, \n",
    "    PiecewisePolynomial,\n",
    "    PiecewisePose,\n",
    "    JacobianWrtVariable,\n",
    "    StartMeshcat,\n",
    "    TrajectorySource,\n",
    "    Integrator,\n",
    "    \n",
    ")\n",
    "\n",
    "from manipulation.station import (\n",
    "    LoadScenario,\n",
    "    MakeHardwareStation,\n",
    ")\n",
    "import h5py\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24aeb0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Meshcat listening for connections at http://localhost:7001\n"
     ]
    }
   ],
   "source": [
    "meshcat = StartMeshcat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb5139b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_drawer_pose(\n",
    "    r_min=0.37,      \n",
    "    r_max=0.47,     \n",
    "    fov_deg=90, \n",
    "    face_noise_deg=30,\n",
    "    cabinet_depth=1,\n",
    "    cabinet_width=1,    \n",
    "):\n",
    "    \"\"\"\n",
    "    Returns (x, y, yaw_degrees)\n",
    "    \"\"\"\n",
    "    r = random.uniform(r_min, r_max)\n",
    "    theta_rad = np.radians(random.uniform(270-fov_deg/2, 270+fov_deg/2))\n",
    "    \n",
    "    x = r * np.cos(theta_rad)\n",
    "    y = r * np.sin(theta_rad)\n",
    "    \n",
    "    \n",
    "    # Adjust angle b/w drawer origin is bottom right corner of cabinet\n",
    "    perfect_yaw_rad = np.arctan2(-y, -x)\n",
    "    yaw_rad = perfect_yaw_rad + np.radians(random.uniform(-face_noise_deg, face_noise_deg))\n",
    "    \n",
    "    local_center_x = cabinet_depth / 2.0\n",
    "    local_center_y = cabinet_width / 2.0\n",
    "    \n",
    "    c_yaw = np.cos(yaw_rad)\n",
    "    s_yaw = np.sin(yaw_rad)\n",
    "    \n",
    "    world_offset_x = local_center_x * c_yaw - local_center_y * s_yaw\n",
    "    world_offset_y = local_center_x * s_yaw + local_center_y * c_yaw\n",
    "    \n",
    "    final_origin_x = x - world_offset_x\n",
    "    final_origin_y = y - world_offset_y\n",
    "    \n",
    "    return final_origin_x, final_origin_y, np.degrees(yaw_rad)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7aa53dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:drake:Drake materials have been assigned to a glTF file. glTF defines its own materials, so post hoc materials will be ignored and should be removed from the model specification. glTF file: '/home/kelly_lucy/.cache/drake/package_map/4c7310cd9812b812333cc24487bf6f4828db01c6313f29a9e252b0acf689f600-9ec35424f52179993161352be1d5690cd08db62caa28bd0f556a2302977a703f/wsg_50_description/meshes/wsg_body.gltf'\n",
      "WARNING:drake:warning: material [ 'None.005' ] not found in .mtl\n",
      "material [ 'None_NONE.006' ] not found in .mtl\n",
      "\n",
      "WARNING:drake:Drake materials have been assigned to a glTF file. glTF defines its own materials, so post hoc materials will be ignored and should be removed from the model specification. glTF file: '/home/kelly_lucy/.cache/drake/package_map/4c7310cd9812b812333cc24487bf6f4828db01c6313f29a9e252b0acf689f600-9ec35424f52179993161352be1d5690cd08db62caa28bd0f556a2302977a703f/wsg_50_description/meshes/finger_with_tip.gltf'\n",
      "WARNING:drake:Drake materials have been assigned to a glTF file. glTF defines its own materials, so post hoc materials will be ignored and should be removed from the model specification. glTF file: '/home/kelly_lucy/.cache/drake/package_map/4c7310cd9812b812333cc24487bf6f4828db01c6313f29a9e252b0acf689f600-9ec35424f52179993161352be1d5690cd08db62caa28bd0f556a2302977a703f/wsg_50_description/meshes/finger_with_tip.gltf'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pydrake.systems.analysis.SimulatorStatus at 0x7a6622b37af0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_scenario_string(drawer_name = \"label62\", **kwargs) -> str:\n",
    "    drawer_urdf_path = f\"{Path.cwd()}/urdf/custom/output/{drawer_name}.urdf\"\n",
    "    \n",
    "    x, y, yaw = get_random_drawer_pose(**kwargs)\n",
    "    \n",
    "    scenario_string = f\"\"\"\n",
    "    directives:\n",
    "    # add robot\n",
    "    - add_model:\n",
    "        name: iiwa\n",
    "        file: package://drake_models/iiwa_description/urdf/iiwa14_primitive_collision.urdf\n",
    "        default_joint_positions:\n",
    "            iiwa_joint_1: [-1.57]\n",
    "            iiwa_joint_2: [0.1]\n",
    "            iiwa_joint_3: [0]\n",
    "            iiwa_joint_4: [-1.2]\n",
    "            iiwa_joint_5: [0]\n",
    "            iiwa_joint_6: [1.6]\n",
    "            iiwa_joint_7: [0]\n",
    "    - add_weld:\n",
    "        parent: world\n",
    "        child: iiwa::iiwa_link_0\n",
    "\n",
    "    # add gripper\n",
    "    - add_model:\n",
    "        name: wsg\n",
    "        file: package://manipulation/hydro/schunk_wsg_50_with_tip.sdf\n",
    "    - add_weld:\n",
    "        parent: iiwa::iiwa_link_7\n",
    "        child: wsg::body\n",
    "        X_PC:\n",
    "            translation: [0, 0, 0.09]\n",
    "            rotation: !Rpy {{ deg: [90, 0, 90]}}\n",
    "\n",
    "    # add camera mounted to world \n",
    "    - add_frame:\n",
    "        name: camera0_origin\n",
    "        X_PF:\n",
    "            base_frame: world\n",
    "            rotation: !Rpy {{ deg: [250, 0, 180.0]}}\n",
    "            translation: [0, 2, 1.4]\n",
    "    - add_model:\n",
    "        name: camera0\n",
    "        file: package://manipulation/camera_box.sdf\n",
    "    - add_weld:\n",
    "        parent: camera0_origin\n",
    "        child: camera0::base\n",
    "\n",
    "    # add camera mounted to robot wrist\n",
    "    - add_frame:\n",
    "        name: camera_wrist\n",
    "        X_PF:\n",
    "            base_frame: iiwa::iiwa_link_7\n",
    "            translation: [-0.05, 0, 0.1]   \n",
    "            rotation: !Rpy {{deg: [0, 0, -90]}}\n",
    "    - add_model:\n",
    "        name: camera1\n",
    "        file: package://manipulation/camera_box.sdf\n",
    "    - add_weld:\n",
    "        parent: iiwa::camera_wrist\n",
    "        child: camera1::base\n",
    "\n",
    "    # add camera mounted to world pointing top down\n",
    "    - add_frame:\n",
    "        name: camera2_origin\n",
    "        X_PF:\n",
    "            base_frame: world\n",
    "            rotation: !Rpy {{ deg: [0, 180.0, 0.0]}}\n",
    "            translation: [0, -0.5, 3.0]\n",
    "    - add_model:\n",
    "        name: camera2\n",
    "        file: package://manipulation/camera_box.sdf\n",
    "    - add_weld:\n",
    "        parent: camera2_origin\n",
    "        child: camera2::base\n",
    "        \n",
    "    # add random drawer\n",
    "    - add_model:\n",
    "        name: drawer\n",
    "        file: file://{drawer_urdf_path}\n",
    "    - add_frame:\n",
    "        name: drawer_origin\n",
    "        X_PF:\n",
    "            base_frame: world\n",
    "            translation: [{x}, {y}, 0]    \n",
    "            rotation: !Rpy {{ deg: [0, 0, {yaw}]}}  \n",
    "    - add_weld:\n",
    "        parent: drawer_origin\n",
    "        child: drawer::base_link\n",
    "        \n",
    "    cameras:\n",
    "        camera0:\n",
    "            name: camera0\n",
    "            depth: True\n",
    "            X_PB:\n",
    "                base_frame: camera0::base\n",
    "        camera1:\n",
    "            name: camera1\n",
    "            depth: True\n",
    "            X_PB:\n",
    "                base_frame: camera1::base\n",
    "        camera2:\n",
    "            name: camera2\n",
    "            depth: True\n",
    "            X_PB:\n",
    "                base_frame: camera2::base\n",
    "    \n",
    "    model_drivers:\n",
    "        iiwa: !IiwaDriver\n",
    "            control_mode: position_only \n",
    "            hand_model_name: wsg\n",
    "        wsg: !SchunkWsgDriver {{}}\n",
    "    \"\"\"\n",
    "    return scenario_string\n",
    "\n",
    "scenario_string = generate_scenario_string()\n",
    "scenario = LoadScenario(data=scenario_string)\n",
    "station = MakeHardwareStation(scenario, meshcat=meshcat)\n",
    "builder = DiagramBuilder()\n",
    "builder.AddSystem(station)\n",
    "diagram = builder.Build()\n",
    "context = diagram.CreateDefaultContext()\n",
    "\n",
    "simulator = Simulator(diagram)\n",
    "simulator.set_target_realtime_rate(1.0)\n",
    "simulator.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03e6f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grasp_pose(X_WO: RigidTransform) -> tuple[RigidTransform, RigidTransform]:\n",
    "    p_OG = np.array([0.12, 0, 0])\n",
    "    R_OG = RotationMatrix.MakeZRotation(np.pi/2).multiply(RotationMatrix.MakeYRotation(np.pi))\n",
    "    X_OG = RigidTransform(R_OG, p_OG)\n",
    "    X_WG = X_WO @ X_OG\n",
    "    return X_WG\n",
    "\n",
    "def goal_pose(X_W_Grasporiginal: RigidTransform\n",
    ") -> RigidTransform:\n",
    "    X_Grasporiginal_Graspgoal = RigidTransform(RotationMatrix().Identity(), [0, -0.3, 0])\n",
    "    X_W_Graspgoal = X_W_Grasporiginal @ X_Grasporiginal_Graspgoal\n",
    "    return X_W_Graspgoal\n",
    "\n",
    "def approach_pose(X_WG: RigidTransform) -> RigidTransform:\n",
    "    p_GGApproach = [0, -0.1, 0]\n",
    "    X_GGApproach = RigidTransform(RotationMatrix(), p_GGApproach)\n",
    "    X_WGApproach = X_WG @ X_GGApproach\n",
    "    return X_WGApproach\n",
    "\n",
    "def post_goal_pose(X_WGgoal: RigidTransform) -> RigidTransform:\n",
    "    p_Ggoal_Gpostgoal = [0, -0.2, 0]\n",
    "    X_Ggoal_Gpostgoal = RigidTransform(RotationMatrix(), p_Ggoal_Gpostgoal)\n",
    "    X_WGPost = X_WGgoal @ X_Ggoal_Gpostgoal\n",
    "    return X_WGPost\n",
    "\n",
    "def make_trajectory_pose(\n",
    "    X_Gs: list[RigidTransform], finger_values: np.ndarray, sample_times: list[float]\n",
    ") -> tuple[Trajectory, PiecewisePolynomial]:\n",
    "    poses = PiecewisePose.MakeLinear(sample_times, X_Gs)\n",
    "    \n",
    "    robot_velocity_trajectory = poses.MakeDerivative()\n",
    "    traj_wsg_command = PiecewisePolynomial.FirstOrderHold(sample_times, finger_values)\n",
    "    return robot_velocity_trajectory, traj_wsg_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a100b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoInverseController(LeafSystem):\n",
    "    def __init__(self, plant: MultibodyPlant):\n",
    "        LeafSystem.__init__(self)\n",
    "        self._plant = plant\n",
    "        self._plant_context = plant.CreateDefaultContext()\n",
    "        self._iiwa = plant.GetModelInstanceByName(\"iiwa\")\n",
    "        self._G = plant.GetBodyByName(\"body\").body_frame() \n",
    "        self._W = plant.world_frame()\n",
    "\n",
    "        # Declaring the ports\n",
    "        self.V_G_port = self.DeclareVectorInputPort(\"V_WG\", 6)\n",
    "        self.q_port = self.DeclareVectorInputPort(\"iiwa.position\", 7)\n",
    "        self.DeclareVectorOutputPort(\"iiwa.velocity\", 7, self.CalcOutput)\n",
    "        self.iiwa_start = plant.GetJointByName(\"iiwa_joint_1\").velocity_start()\n",
    "        self.iiwa_end = plant.GetJointByName(\"iiwa_joint_7\").velocity_start()\n",
    "\n",
    "    def CalcOutput(self, context: Context, output: BasicVector):\n",
    "        \"\"\"\n",
    "        Calculates the desired joint velocities q_dot using the pseudo-inverse Jacobian.\n",
    "        \"\"\"\n",
    "        V_WG_desired = self.V_G_port.Eval(context)\n",
    "        q = self.q_port.Eval(context)\n",
    "        self._plant.SetPositions(self._plant_context, self._iiwa, q)\n",
    "\n",
    "        # Using the jacobian to determine the desired joint velocity\n",
    "        J_G_W = self._plant.CalcJacobianSpatialVelocity(\n",
    "            self._plant_context,\n",
    "            JacobianWrtVariable.kQDot,\n",
    "            self._G, \n",
    "            [0, 0, 0], \n",
    "            self._W, \n",
    "            self._W,\n",
    "        )\n",
    "        \n",
    "        # Extract the values corresponding to the IIWA joints\n",
    "        J_WG_iiwa = J_G_W[:, self.iiwa_start : self.iiwa_end + 1]\n",
    "        J_dagger = np.linalg.pinv(J_WG_iiwa)\n",
    "\n",
    "        v = J_dagger @ V_WG_desired\n",
    "        \n",
    "        output.SetFromVector(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0be6eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "WSG_MIN = 0.0        # fully closed width (meters)\n",
    "WSG_MAX = 0.1        # fully open width (meters)\n",
    "\n",
    "def normalize_wsg(width):\n",
    "    return np.clip((width - WSG_MIN) / (WSG_MAX - WSG_MIN), 0.0, 1.0)\n",
    "\n",
    "def unnormalize_wsg(norm_width):\n",
    "    return WSG_MIN + norm_width * (WSG_MAX - WSG_MIN)\n",
    "\n",
    "# TODO: figure out real velocity limit in simulation by closing/opening grippers\n",
    "WSG_MAX_SPEED = 0.4  # meters/sec width change\n",
    "\n",
    "def normalize_wsg_velocity(width_velocity):\n",
    "    v = width_velocity / WSG_MAX_SPEED\n",
    "    return np.clip(v, -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b1ca905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trajectory(scenario_string):\n",
    "    # Initializing \n",
    "    scenario = LoadScenario(data=scenario_string)\n",
    "    builder = DiagramBuilder()\n",
    "    station = MakeHardwareStation(scenario, meshcat=meshcat)\n",
    "    builder.AddSystem(station)\n",
    "    plant = station.GetSubsystemByName(\"plant\")\n",
    "\n",
    "    # Get initial poses of gripper and objects\n",
    "    temp_context = station.CreateDefaultContext()\n",
    "    temp_plant_context = plant.GetMyContextFromRoot(temp_context)\n",
    "    drawer_model_instance = plant.GetModelInstanceByName(\"drawer\")\n",
    "    wsg_model = plant.GetModelInstanceByName(\"wsg\")\n",
    "    iiwa_model = plant.GetModelInstanceByName(\"iiwa\")\n",
    "\n",
    "\n",
    "    \n",
    "    handle_body = plant.GetBodyByName(\"handle3\", drawer_model_instance)\n",
    "    X_W_Handle = plant.EvalBodyPoseInWorld(temp_plant_context, handle_body)\n",
    "\n",
    "    gripper_body = plant.GetBodyByName(\"body\", wsg_model)\n",
    "    \n",
    "    \n",
    "    # Designing the poses (expert trajcetory)\n",
    "    X_W_GripInitial = plant.EvalBodyPoseInWorld(temp_plant_context, gripper_body)\n",
    "    X_W_Grasp = grasp_pose(X_W_Handle)\n",
    "    X_W_Pregrasp = approach_pose(X_W_Grasp)\n",
    "    X_W_Graspgoal = goal_pose(X_W_Grasp)\n",
    "    X_W_Gpostgoal = post_goal_pose(X_W_Graspgoal)\n",
    "    \n",
    "    opened = 0.107\n",
    "    closed = 0.0\n",
    "\n",
    "    keyframes = [\n",
    "        (X_W_GripInitial, opened), (X_W_Pregrasp, opened), (X_W_Grasp, opened), \n",
    "        (X_W_Grasp, closed), (X_W_Graspgoal, closed), (X_W_Graspgoal, opened), (X_W_Gpostgoal, opened), (X_W_GripInitial, opened)\n",
    "    ]\n",
    "\n",
    "    \n",
    "    # # Finding and adding the trajectory\n",
    "    gripper_poses = [keyframe[0] for keyframe in keyframes]\n",
    "    finger_states = np.asarray([keyframe[1] for keyframe in keyframes]).reshape(1, -1)\n",
    "    sample_times = [2 * i for i in range(len(gripper_poses))]\n",
    "    traj_V_G, traj_wsg_command = make_trajectory_pose(gripper_poses, finger_states, sample_times)\n",
    "\n",
    "    V_G_source = builder.AddSystem(TrajectorySource(traj_V_G))\n",
    "    wsg_source = builder.AddSystem(TrajectorySource(traj_wsg_command))\n",
    "    controller = builder.AddSystem(PseudoInverseController(plant))\n",
    "    integrator = builder.AddSystem(Integrator(7))\n",
    "\n",
    "\n",
    "    # Connect Ports\n",
    "    builder.Connect(V_G_source.get_output_port(0), controller.GetInputPort(\"V_WG\"))\n",
    "    builder.Connect(station.GetOutputPort(\"iiwa.position_measured\"), controller.GetInputPort(\"iiwa.position\"))\n",
    "    builder.Connect(controller.get_output_port(0), integrator.get_input_port(0))\n",
    "    \n",
    "    # Crucial: We are connecting Integrator -> Station. \n",
    "    # This means the Integrator Output IS the Action.\n",
    "    builder.Connect(integrator.get_output_port(0), station.GetInputPort(\"iiwa.position\"))\n",
    "    builder.Connect(wsg_source.get_output_port(0), station.GetInputPort(\"wsg.position\"))\n",
    "\n",
    "    diagram = builder.Build()\n",
    "\n",
    "    # Define the simulator\n",
    "    simulator = Simulator(diagram)\n",
    "    context = simulator.get_mutable_context()\n",
    "    station_context = station.GetMyContextFromRoot(context)\n",
    "    integrator.set_integral_value(\n",
    "        integrator.GetMyContextFromRoot(context),\n",
    "        plant.GetPositions(\n",
    "            plant.GetMyContextFromRoot(context),\n",
    "            iiwa_model,\n",
    "        ),\n",
    "    )\n",
    "    diagram.ForcedPublish(context)\n",
    "    print(f\"sanity check, simulation will run for {traj_V_G.end_time()} seconds\")\n",
    "\n",
    "    # # run simulation\n",
    "    meshcat.StartRecording()\n",
    "    simulator.set_target_realtime_rate(1)\n",
    "\n",
    "    # 5. DATA LOGGING SETUP\n",
    "    target_dt = 0.05 # 20 Hz\n",
    "    image_data_camera0 = []\n",
    "    image_data_camera1 = []\n",
    "    image_data_camera2 = []\n",
    "    timestamps = []\n",
    "    qpos_list = []\n",
    "    qvel_list = []\n",
    "    action_list = []\n",
    "\n",
    "    total_duration = traj_V_G.end_time()\n",
    "    print(f\"Starting collection... running for {total_duration} seconds.\")\n",
    "\n",
    "    # 6. EXECUTION LOOP\n",
    "    t = 0.0\n",
    "    \n",
    "    while t <= total_duration:\n",
    "        simulator.AdvanceTo(t)\n",
    "        t = simulator.get_context().get_time()\n",
    "\n",
    "        sim_context = simulator.get_context()\n",
    "        station_context = diagram.GetSubsystemContext(station, sim_context)\n",
    "        plant_context = station.GetSubsystemContext(plant, station_context)\n",
    "        \n",
    "        # iiwa joints\n",
    "        q_iiwa = plant.GetPositions(plant_context, iiwa_model)\n",
    "        v_iiwa = plant.GetVelocities(plant_context, iiwa_model)\n",
    "        \n",
    "        # gripper joins\n",
    "        q_wsg = plant.GetPositions(plant_context, wsg_model)\n",
    "        v_wsg = plant.GetVelocities(plant_context, wsg_model)\n",
    "        wsg_width = normalize_wsg(q_wsg[1] - q_wsg[0])\n",
    "        wsg_vel = normalize_wsg_velocity(v_wsg[1] - v_wsg[0])\n",
    "\n",
    "        # concatenate to get exactly (7 + 1,) vectors\n",
    "        qpos = np.concatenate([q_iiwa, [wsg_width]], axis=0).copy()\n",
    "        qvel = np.concatenate([v_iiwa, [wsg_vel]], axis=0).copy()\n",
    "        qpos_list.append(qpos)\n",
    "        qvel_list.append(qvel)\n",
    "\n",
    "        # D. Get Actions (Commands)\n",
    "        # We extract what the controller/trajectory is SENDING to the robot this step.\n",
    "        # For iiwa: Output of Integrator\n",
    "        integrator_context = diagram.GetSubsystemContext(integrator, sim_context)\n",
    "        iiwa_cmd = integrator.get_output_port(0).Eval(integrator_context)\n",
    "        \n",
    "        # For wsg: Output of TrajectorySource\n",
    "        wsg_source_context = diagram.GetSubsystemContext(wsg_source, sim_context)\n",
    "        wsg_cmd_raw = wsg_source.get_output_port(0).Eval(wsg_source_context)\n",
    "        wsg_cmd_norm = normalize_wsg(wsg_cmd_raw[0]) # Normalize strictly for data consistency\n",
    "\n",
    "        # Flatten and concatenate\n",
    "        iiwa_cmd_np = np.asarray(iiwa_cmd).ravel()\n",
    "        wsg_cmd_np = np.asarray([wsg_cmd_norm]).ravel()\n",
    "        action = np.concatenate([iiwa_cmd_np, wsg_cmd_np], axis=0)\n",
    "        action_list.append(action)\n",
    "\n",
    "        # E. Get Images\n",
    "        # Camera 0\n",
    "        img0 = station.GetOutputPort(\"camera0.rgb_image\").Eval(station_context)\n",
    "        np_img0 = np.array(np.copy(img0.data)).reshape(img0.height(), img0.width(), -1)\n",
    "        image_data_camera0.append(np_img0[:, :, :3].copy()) # Keep RGB only\n",
    "        \n",
    "        # Camera 1\n",
    "        img1 = station.GetOutputPort(\"camera1.rgb_image\").Eval(station_context)\n",
    "        np_img1 = np.array(np.copy(img1.data)).reshape(img1.height(), img1.width(), -1)\n",
    "        image_data_camera1.append(np_img1[:, :, :3].copy())\n",
    "\n",
    "        # Camera 2\n",
    "        img2 = station.GetOutputPort(\"camera2.rgb_image\").Eval(station_context)\n",
    "        np_img2 = np.array(np.copy(img2.data)).reshape(img2.height(), img2.width(), -1)\n",
    "        image_data_camera2.append(np_img2[:, :, :3].copy())\n",
    "\n",
    "        timestamps.append(t)\n",
    "        t += target_dt\n",
    "\n",
    "    print(\"Trajectory execution and logging complete.\")\n",
    "    meshcat.StopRecording()\n",
    "    meshcat.PublishRecording()\n",
    "\n",
    "    # 7. Return Dictionary (Standard ACT/Imitation Learning format)\n",
    "    return {\n",
    "        \"qpos\": qpos_list,\n",
    "        \"qvel\": qvel_list,\n",
    "        \"action\": action_list,\n",
    "        \"images\": {\n",
    "            \"camera0\": image_data_camera0,\n",
    "            \"camera1\": image_data_camera1,\n",
    "            \"camera2\": image_data_camera2\n",
    "        },\n",
    "        \"timestamp\": timestamps\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d2638d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trajectory_data(data: dict, episode_idx: int = 0):\n",
    "    # ---------- convert buffers to numpy arrays ----------\n",
    "    qpos_arr = np.stack(data['qpos'], axis=0).astype(np.float32)      # (T, nq)\n",
    "    qvel_arr = np.stack(data['qvel'], axis=0).astype(np.float32)      # (T, nq)\n",
    "    action_arr = np.stack(data['action'], axis=0).astype(np.float32)  # (T, act_dim)\n",
    "\n",
    "    images0_arr = np.stack(data['images']['camera0'], axis=0).astype(np.uint8)  # (T, H, W, 3)\n",
    "    images1_arr = np.stack(data['images']['camera1'], axis=0).astype(np.uint8)  # (T, H, W, 3)\n",
    "    images2_arr = np.stack(data['images']['camera2'], axis=0).astype(np.uint8)  # (T, H, W, 3)\n",
    "\n",
    "    timestamps_arr = np.array(data['timestamp'], dtype=np.float64)\n",
    "\n",
    "    # ---------- write ACT-style HDF5 episode ----------\n",
    "    h5_path = os.path.join(\"teleop_data/sim_open_drawer\", f\"episode_{episode_idx}.hdf5\")\n",
    "    print(\"Saving episode to \", h5_path)\n",
    "\n",
    "    with h5py.File(h5_path, \"w\") as root:\n",
    "        # mark this as simulation data (ACT uses this flag)\n",
    "        root.attrs[\"sim\"] = True\n",
    "\n",
    "        # actions: shape (T, act_dim)\n",
    "        root.create_dataset(\"action\", data=action_arr, compression=\"gzip\")\n",
    "\n",
    "    # observations group\n",
    "        obs_grp = root.create_group(\"observations\")\n",
    "        obs_grp.create_dataset(\"qpos\", data=qpos_arr, compression=\"gzip\")\n",
    "        obs_grp.create_dataset(\"qvel\", data=qvel_arr, compression=\"gzip\")\n",
    "\n",
    "        # optional: store timestamps (not strictly required by ACT but often useful)\n",
    "        obs_grp.create_dataset(\"time\", data=timestamps_arr)\n",
    "\n",
    "        # images subgroup, one dataset per camera\n",
    "        img_grp = obs_grp.create_group(\"images\")\n",
    "        img_grp.create_dataset(\"camera0\", data=images0_arr, compression=\"gzip\")\n",
    "        img_grp.create_dataset(\"camera1\", data=images1_arr, compression=\"gzip\")\n",
    "        img_grp.create_dataset(\"camera2\", data=images2_arr, compression=\"gzip\")\n",
    "\n",
    "    print(f\"Wrote ACT-style episode to {h5_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7ee2480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:drake:Drake materials have been assigned to a glTF file. glTF defines its own materials, so post hoc materials will be ignored and should be removed from the model specification. glTF file: '/home/kelly_lucy/.cache/drake/package_map/4c7310cd9812b812333cc24487bf6f4828db01c6313f29a9e252b0acf689f600-9ec35424f52179993161352be1d5690cd08db62caa28bd0f556a2302977a703f/wsg_50_description/meshes/wsg_body.gltf'\n",
      "WARNING:drake:warning: material [ 'None.005' ] not found in .mtl\n",
      "material [ 'None_NONE.006' ] not found in .mtl\n",
      "\n",
      "WARNING:drake:Drake materials have been assigned to a glTF file. glTF defines its own materials, so post hoc materials will be ignored and should be removed from the model specification. glTF file: '/home/kelly_lucy/.cache/drake/package_map/4c7310cd9812b812333cc24487bf6f4828db01c6313f29a9e252b0acf689f600-9ec35424f52179993161352be1d5690cd08db62caa28bd0f556a2302977a703f/wsg_50_description/meshes/finger_with_tip.gltf'\n",
      "WARNING:drake:Drake materials have been assigned to a glTF file. glTF defines its own materials, so post hoc materials will be ignored and should be removed from the model specification. glTF file: '/home/kelly_lucy/.cache/drake/package_map/4c7310cd9812b812333cc24487bf6f4828db01c6313f29a9e252b0acf689f600-9ec35424f52179993161352be1d5690cd08db62caa28bd0f556a2302977a703f/wsg_50_description/meshes/finger_with_tip.gltf'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating episode 0...\n",
      "sanity check, simulation will run for 14.0 seconds\n",
      "Starting collection... running for 14.0 seconds.\n",
      "Trajectory execution and logging complete.\n",
      "Saving episode to  teleop_data/sim_open_drawer/episode_0.hdf5\n",
      "Wrote ACT-style episode to teleop_data/sim_open_drawer/episode_0.hdf5\n",
      "Episode 0 complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    meshcat.Delete()\n",
    "    print(f\"Generating episode {i}...\")\n",
    "    # scenario_string = generate_scenario_string(fov_deg = 0, face_noise_deg=0)\n",
    "    scenario_string = generate_scenario_string()\n",
    "    trajectory_data = generate_trajectory(scenario_string)\n",
    "    save_trajectory_data(trajectory_data, episode_idx=i)\n",
    "    print(f\"Episode {i} complete.\\n\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab9eac7",
   "metadata": {},
   "source": [
    "### Watching the demonstration back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c62f6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio; \n",
    "from IPython.display import Video; \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60198a96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find a backend to open `episode_playback.mp4`` with iomode `wI`.\nBased on the extension, the following plugins might add capable backends:\n  FFMPEG:  pip install imageio[ffmpeg]\n  pyav:  pip install imageio[pyav]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m     frame \u001b[38;5;241m=\u001b[39m data[i]\n\u001b[1;32m      8\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepisode_playback.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m; \n\u001b[1;32m     12\u001b[0m Video(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_playback.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m480\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m360\u001b[39m) \n",
      "File \u001b[0;32m~/Desktop/manipulation_project/env/lib/python3.13/site-packages/imageio/v2.py:494\u001b[0m, in \u001b[0;36mmimwrite\u001b[0;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m imopen_args \u001b[38;5;241m=\u001b[39m decypher_format_arg(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    493\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimopen_args\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mwrite(ims, is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/manipulation_project/env/lib/python3.13/site-packages/imageio/core/imopen.py:281\u001b[0m, in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    276\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBased on the extension, the following plugins might add capable backends:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall_candidates\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[1;32m    280\u001b[0m request\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err_type(err_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find a backend to open `episode_playback.mp4`` with iomode `wI`.\nBased on the extension, the following plugins might add capable backends:\n  FFMPEG:  pip install imageio[ffmpeg]\n  pyav:  pip install imageio[pyav]"
     ]
    }
   ],
   "source": [
    "file_path = \"teleop_data/sim_open_drawer/episode_0.hdf5\"\n",
    "\n",
    "f = h5py.File(file_path, \"r\")\n",
    "data = f['observations']['images']['camera0']\n",
    "frames = []\n",
    "for i in range(data.shape[0]):\n",
    "    frame = data[i]\n",
    "    frames.append(frame)\n",
    "    \n",
    "\n",
    "imageio.mimwrite('episode_playback.mp4', data, fps=30); \n",
    "Video('episode_playback.mp4', width=480, height=360) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5c323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc9526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21169ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
